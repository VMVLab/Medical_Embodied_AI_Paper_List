<div align=center>
<img src="img\logo.png" width="180px">
</div>
<h2 align="center"><a src="paper\medical_embodied_ai.pdf"> Towards Next-Generation Healthcare: A Survey of Medical Embodied AI for Perception, Decision-Making, and Action </a></h2>
<h5 align="center"> If you like our project, please give us a star ‚≠ê on GitHub for the latest update.</h5>

## üè† About

Foundation models have demonstrated impressive performance in enhancing  healthcare efficiency. However, their limited ability to perceive and interact  with the physical world significantly constrains their utility in real-world clinical  workflows. Recently, embodied artificial intelligence (AI) provides a promising  physical-interactive paradigm for intelligent healthcare by integrating percep tion, decision-making, and action within a closed-loop system. Nevertheless, the  exploration of embodied AI for healthcare is still in its infancy. To support these  advances, this review systematically surveys the key components of embodied AI,  focusing on the integration of perception, decision-making, and action. Addition ally, we present a comprehensive overview of representative medical applications,  relevant datasets, major challenges in clinical practice, and further discuss the  key directions for future research in this emerging field. The associated project  can be found at XXXX.

<div align="center">

### [1. Introduction](#1-introduction) | [2. Embodied AI](#2-embodied-ai) |  [3. Embodied AI in Medicine](#3-embodied-ai-in-medicine)

### [4. Datasets and benchmark](#4-datasets-and-benchmark) | [5. Challenges and Outlook](#5-challenges-and-outlook) | [6. Conclusion](#6-conclusion)

</div>

## 1. Introduction

* [1][**Nature medicine, 2024**] Artificial intelligence in surgery [paper](https://www.nature.com/articles/s41591-024-02970-3)
* ‚Äã**[1][**Nature Medicine, 2024**] Artificial intelligence in surgery** [paper]([https://www.google.com/url?sa=E&q=placeholder](https://www.nature.com/articles/s41591-024-02970-3))
  ‚Äã
* ‚Äã**[2][**Nature Medicine, 2023**] A deep learning algorithm to classify skin lesions from mpox virus infection** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[3][**Nature Methods, 2021**] nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[4][**Nature, 2025**] A fully open AI foundation model applied to chest radiography** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[5][**Nature Reviews Bioengineering, 2025**] Application of large language models in medicine** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[6][**Nature Medicine, 2025**] Toward expert-level medical question answering with large language models** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[7][**Nature Medicine, 2025**] A generalist medical language model for disease diagnosis assistance** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[8][**IEEE/ASME Transactions on Mechatronics, 2025**] Aligning cyber space with physical world: A comprehensive survey on embodied AI** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[9][**Nature Communications, 2025**] AI-embodied multi-modal flexible electronic robots with programmable sensing, actuating and self-learning** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[10][**Science Robotics, 2025**] Surgical embodied intelligence for generalized task autonomy in laparoscopic robot-assisted surgery** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[11][**Proceedings of the IEEE, 2022**] Concepts and trends in autonomy for robot-assisted surgery** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[12][**IEEE Transactions on Automation Science and Engineering, 2025**] Sim2real learning with domain randomization for autonomous guidewire navigation in robotic-assisted endovascular procedures** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[13][**IEEE Transactions on Fuzzy Systems, 2025**] Multi-agent fuzzy reinforcement learning with LLM for cooperative navigation of endovascular robotics** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[14][**IEEE Transactions on Robotics, 2023**] Autonomous navigation for robot-assisted intraluminal and endovascular procedures: A systematic review** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[15][**ICRA, 2025**] VascularPilot3D: Toward a 3D fully autonomous navigation for endovascular robotics** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[16][**ICRA, 2025**] SLAM assisted 3D tracking system for laparoscopic surgery** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[17][**CISS, 2025**] Informative path planning for nano-surgical robot adaptive drug delivery** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[18][**IEEE Transactions on Affective Computing, 2025**] Affective embodied agent for patient assistance in virtual rehabilitation** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[19][**i-CREATe, 2024**] Virtual co-embodiment rehabilitation: An innovative method integrating virtual co-embodiment and action observation therapy in virtual reality rehabilitation** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[20][**Journal of Medical Internet Research, 2024**] Embodied conversational agents for chronic diseases: scoping review** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[21][**Journal of British Surgery, 2015**] Robotic surgery** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[22][**IEEE Transactions on Robotics, 2024**] Using fiber optic bundles to miniaturize vision-based tactile sensors** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[23][**Nature, 2024**] Experiment-free exoskeleton assistance via learning in simulation** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[24][**IEEE Transactions on Systems, Man, and Cybernetics: Systems, 2025**] Reinforcement learning methods for assistive and rehabilitation robotic systems: A survey** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[25][**AIM, 2025**] Based therapist skill transfer learning framework for upper-limb rehabilitation exoskeleton** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[26][**Frontiers in Bioengineering and Biotechnology, 2025**] AI-driven hybrid rehabilitation: synergizing robotics and electrical stimulation for upper-limb recovery after stroke** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[27][**APMS, 2020**] Autonomous mobile robots in hospital logistics** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[28][**Autonomous Robots, 2024**] Boosting the hospital by integrating mobile robotic assistance systems: a comprehensive classification of the risks to be addressed** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[29][**IC-BIS, 2024**] Research on multirobot collaboration platform for logistic distribution of medical consumables in the operating room** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[30][**ICSR, 2024**] Interaction matters when it comes to hand disinfection using robots at hospitals** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[31][**arXiv, 2025**] Large model empowered embodied AI: A survey on decision-making and embodied learning** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[32][**arXiv, 2025**] Towards robust and secure embodied AI: A survey on vulnerabilities and attacks** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[33][**arXiv, 2025**] UAVs meet agentic AI: A multidomain survey of autonomous aerial intelligence and agentic UAVs** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[34][**arXiv, 2025**] Embodied AI: From LLMs to world models** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[35][**DTPI, 2024**] Embodied intelligent driving: Key technologies and applications** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[36][**arXiv, 2025**] Multi-agent autonomous driving systems with large language models: A survey of recent advances** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã
* ‚Äã**[37][**Information Fusion, 2025**] From screens to scenes: A survey of embodied AI in healthcare** [paper](https://www.google.com/url?sa=E&q=placeholder)
  
  ‚Äã

## 2. Embodied AI

### 2.1 Embodied Perception

#### 2.1.1 Object Perception

#### 2.1.2 Scene Perception

#### 2.1.3 Behavior Perception

#### 2.1.4 Expression Perception

### 2.2 Embodied Decision-Making

#### 2.2.1 Task Planning

#### 2.2.2 Embodied Navigation

#### 2.2.3 Embodied Question Answering (EQA)

### 2.3 Embodied Action

#### 2.3.1 Imitation Learning-Based Action

#### 2.3.2 Reinforcement Learning-Based Action

#### 2.3.3 Large Model-Driven Action

## 3. Embodied AI in Medicine

### 3.1 Medical Embodied Perception

#### 3.1.1 Medical Instrument and Organ Recognition

#### 3.1.2 Surgical and Clinical Environment Perception and Modeling

#### 3.1.3 Medical Operation Behavior Detection

#### 3.1.4 Emotional Interaction Understanding

### 3.2 Medical Embodied Decision-Making

#### 3.2.1 Medical Workflow Modeling and Task Planning

#### 3.2.2 Medical Navigation Systems

#### 3.2.3 Clinical Question-answering and Decision Support

### 3.3 Medical Embodied Action

#### 3.3.1 Medical Imitation-based Action

#### 3.3.2 Medical Reinforcement-based Action

#### 3.3.3 Medical Large Model-Driven Action

### 3.4 Integrated Application Scenarios in Healthcare

#### 3.4.1 Surgical Robot

#### 3.4.2 Intelligent Caregiving and Companion Robot

#### 3.4.3 Immersive Medical Education Platform

#### 3.4.4 Telecollaborative Diagnostic and Treatment System

## 4. Datasets and benchmark

### 4.1 Perception Datasets

#### 4.1.1 Organ‚ÄìInstrument Recognition Datasets

#### 4.1.2 Medical Scene Modeling Datasets

#### 4.1.3 Clinical Action and Pose Estimation Datasets

#### 4.1.4 Multimodal Affective Perception Datasets

### 4.2 Decision-Making Datasets

#### 4.2.1 Surgical Workflow Annotation Datasets

#### 4.2.2 Medical Navigation Datasets

#### 4.2.3 Medical Question Answering Datasets

### 4.3 Action Datasets

### 4.4 Simulation Platforms and Synthetic Datasets

#### 4.4.1 Surgical Simulation Platforms

#### 4.4.2 Synthetic Datasets


